{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c0787532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os, sys\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43da9b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "HOME_DIRECTORY=os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "os.chdir(HOME_DIRECTORY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "df13f9e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # sync ids with nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\" \n",
    "os.environ[\"MKL_SERVICE_FORCE_INTEL\"]=\"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bda32311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# script params\n",
    "port=5219\n",
    "sampling_fn=\"random\"\n",
    "lSet_partition=1\n",
    "base_seed=1\n",
    "num_GPU=1\n",
    "al_iterations=4\n",
    "num_aml_trials=5 #50\n",
    "budget_size=5000 #2500\n",
    "\n",
    "dataset=\"CIFAR10\"\n",
    "init_partition=10\n",
    "step_partition=10\n",
    "clf_epochs=5 #150\n",
    "num_classes=10\n",
    "swa_lr=5e-4\n",
    "swa_freq=50\n",
    "swa_epochs=5 #50\n",
    "\n",
    "log_iter=40\n",
    "\n",
    "#Data arguments\n",
    "train_dir=f\"{HOME_DIRECTORY}/data/{dataset}/train-{dataset}/\"\n",
    "test_dir=f\"{HOME_DIRECTORY}/data/{dataset}/test-{dataset}/\"\n",
    "lSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/lSet_{dataset}.npy\"\n",
    "uSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/uSet_{dataset}.npy\"\n",
    "valSetPath=f\"{HOME_DIRECTORY}/data/{dataset}/partition_{lSet_partition}/valSet_{dataset}.npy\"\n",
    "\n",
    "out_dir=f\"{HOME_DIRECTORY}/sample_results_aml_rn18\"\n",
    "\n",
    "model_style=\"resnet_style\"\n",
    "model_type=\"resnet_2\"\n",
    "model_depth=18\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1a24cdd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========= [NO ADVANCED REGULARIZATION TRICK ACTIVATED] =========\n",
      "~~~ out_dir:  /home/azeez/Documents/TorchAL/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla\n",
      "check_aml_path: \n",
      "/home/azeez/Documents/TorchAL/sample_results_aml_rn18/best_automl_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/checkpoints\n",
      "tempArgsFile: /tmp/auto_ml_sp_t8v5iu4n.pkl\n",
      "scriptname: /home/azeez/Documents/TorchAL/tools/auto_ml_exit.py\n",
      "~~ check_dir:  /home/azeez/Documents/TorchAL/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla\n",
      "==> Expected number of trials: 5\n",
      "==> Found number of trials: 1\n",
      "\u001b[32m[I 2023-11-25 13:20:45,677]\u001b[0m A new study created in memory with name: no-name-73c18836-5a23-4abf-8574-992bd358a35e\u001b[0m\n",
      "Sampler used:  RandomSampler\n",
      "== al_model_phase: False ==\n",
      "/home/azeez/Documents/TorchAL/tools/auto_ml_exit.py:158: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "/home/azeez/Documents/TorchAL/tools/auto_ml_exit.py:159: FutureWarning:\n",
      "\n",
      "suggest_loguniform has been deprecated in v3.0.0. This feature will be removed in v6.0.0. See https://github.com/optuna/optuna/releases/tag/v3.0.0. Use suggest_float(..., log=True) instead.\n",
      "\n",
      "======== Hyper-params for TRIAL: 0 ========\n",
      "Learning Rate: 0.002301367907216207\n",
      "Weight Decay : 2.4475839381751293e-08\n",
      "Batch Size   : 256\n",
      "Optimizer    : SGD\n",
      "==================================================\n",
      "==== Loading trainDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [RandomHorizontalFlip(p=0.5), ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading valDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "==== Loading noAugDataset ====\n",
      "Dataset is augmented\n",
      "--------------------------------------\n",
      "Preprocess Operations Selected ==>  [ToTensor()]\n",
      "--------------------------------------\n",
      "Files already downloaded and verified\n",
      "===========In custom dum cfg===========\n",
      "temp_cfg.OUT_DIR: /home/azeez/Documents/TorchAL/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla/trial-0/, temp_cfg.CFG_DEST: config.yaml\n",
      "=======================================\n",
      "In building the azeez model\n",
      "cfg.NUM_GPUS: 1\n",
      "torch.cuda.device_count(): 0\n",
      "False\n",
      "\u001b[33m[W 2023-11-25 13:20:48,013]\u001b[0m Trial 0 failed with parameters: {'learning_rate': 0.002301367907216207, 'weight_decay': 2.4475839381751293e-08, 'batch_size': 256, 'optimizer': 'SGD'} because of the following error: AssertionError('Cannot use more GPU devices than available').\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/azeez/miniconda3/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/auto_ml_exit.py\", line 290, in <lambda>\n",
      "    lambda trial: objective(trial, cfg, args, temp_out_dir, isPruning),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/auto_ml_exit.py\", line 257, in objective\n",
      "    best_val_acc, best_val_epoch = al_main(\n",
      "                                   ^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/auto_ml_exit.py\", line 61, in al_main\n",
      "    best_val_acc, best_val_epoch = single_proc_train(\n",
      "                                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/train_al.py\", line 732, in single_proc_train\n",
      "    return train_model(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/train_al.py\", line 353, in train_model\n",
      "    model = model_builder.build_model(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/pycls/core/model_builder.py\", line 169, in build_model\n",
      "    cfg.NUM_GPUS <= torch.cuda.device_count()\n",
      "AssertionError: Cannot use more GPU devices than available\n",
      "\u001b[33m[W 2023-11-25 13:20:48,015]\u001b[0m Trial 0 failed with value None.\u001b[0m\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/auto_ml_exit.py\", line 353, in <module>\n",
      "    run_auto_ml(cfg, args)\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/auto_ml_exit.py\", line 289, in run_auto_ml\n",
      "    study.optimize(\n",
      "  File \"/home/azeez/miniconda3/lib/python3.11/site-packages/optuna/study/study.py\", line 451, in optimize\n",
      "    _optimize(\n",
      "  File \"/home/azeez/miniconda3/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 66, in _optimize\n",
      "    _optimize_sequential(\n",
      "  File \"/home/azeez/miniconda3/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 163, in _optimize_sequential\n",
      "    frozen_trial = _run_trial(study, func, catch)\n",
      "                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azeez/miniconda3/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 251, in _run_trial\n",
      "    raise func_err\n",
      "  File \"/home/azeez/miniconda3/lib/python3.11/site-packages/optuna/study/_optimize.py\", line 200, in _run_trial\n",
      "    value_or_values = func(trial)\n",
      "                      ^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/auto_ml_exit.py\", line 290, in <lambda>\n",
      "    lambda trial: objective(trial, cfg, args, temp_out_dir, isPruning),\n",
      "                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/auto_ml_exit.py\", line 257, in objective\n",
      "    best_val_acc, best_val_epoch = al_main(\n",
      "                                   ^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/auto_ml_exit.py\", line 61, in al_main\n",
      "    best_val_acc, best_val_epoch = single_proc_train(\n",
      "                                   ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/train_al.py\", line 732, in single_proc_train\n",
      "    return train_model(\n",
      "           ^^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/train_al.py\", line 353, in train_model\n",
      "    model = model_builder.build_model(\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/pycls/core/model_builder.py\", line 169, in build_model\n",
      "    cfg.NUM_GPUS <= torch.cuda.device_count()\n",
      "AssertionError: Cannot use more GPU devices than available\n",
      "Number of trials found at /home/azeez/Documents/TorchAL/sample_results_aml_rn18/auto_ml_results/lSet_1/start_1/CIFAR10/10.0/resnet_2_depth_18/vanilla: 1\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/main_aml.py\", line 214, in <module>\n",
      "    main(args)\n",
      "  File \"/home/azeez/Documents/TorchAL/tools/main_aml.py\", line 172, in main\n",
      "    cfg_dir, best_model_path = automl_model_inference(\n",
      "                               ^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/helper/aml_utils.py\", line 44, in automl_model_inference\n",
      "    best_model_path = search_best_model_path(automl_path)\n",
      "                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/azeez/Documents/TorchAL/helper/path_extractor.py\", line 133, in search_best_model_path\n",
      "    best_val_acc_idx = np.argsort(val_acc)[-1]  # -1 to get index for max\n",
      "                       ~~~~~~~~~~~~~~~~~~~^^^^\n",
      "IndexError: index -1 is out of bounds for axis 0 with size 0\n"
     ]
    }
   ],
   "source": [
    "!python3 $HOME_DIRECTORY/tools/main_aml.py --n_GPU $num_GPU \\\n",
    "--port $port --sampling_fn $sampling_fn --lSet_partition $lSet_partition \\\n",
    "--seed_id $base_seed \\\n",
    "--init_partition $init_partition --step_partition $step_partition \\\n",
    "--dataset $dataset --budget_size $budget_size \\\n",
    "--out_dir $out_dir \\\n",
    "--num_aml_trials $num_aml_trials --num_classes $num_classes \\\n",
    "--al_max_iter $al_iterations \\\n",
    "--model_type $model_type --model_depth $model_depth \\\n",
    "--clf_epochs $clf_epochs \\\n",
    "--eval_period 1 --checkpoint_period 1 \\\n",
    "--lSetPath $lSetPath --uSetPath $uSetPath --valSetPath $valSetPath \\\n",
    "--train_dir $train_dir --test_dir $test_dir \\\n",
    "--dropout_iterations 25 \\\n",
    "--cfg configs/$dataset/$model_style/$model_type/R-18_4gpu_unreg.yaml \\\n",
    "--vaal_z_dim 32 --vaal_vae_bs 64 --vaal_epochs 2 \\\n",
    "--vaal_vae_lr 5e-4 --vaal_disc_lr 5e-4 --vaal_beta 1.0 --vaal_adv_param 1.0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342ee282",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
